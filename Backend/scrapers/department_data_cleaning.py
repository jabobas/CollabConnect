"""
Filename: department_data_cleaning.py
Author: Lucas Matheson
Edited by: Lucas Matheson
Date: November 10, 2025


This data is currently in a nested dictionary format, with departments as keys
and people as nested keys within each department. This format is good for inserting 
the data into the relational database by iterating over the dictionary and grabbing 
each object and its properties to insert it into the database using defined procedures.

The data has many properties that can be cleaned and split into multiple columns. For example, 
some projects are apa 7 citations that can be split into authors, year, title, etc. This 
can cover more columns and add more people into the database. 
"""

import json
from pathlib import Path
import re

#  AI generated by ChatGPT to print the data in a readable format
#  Primarily for debugging purposes
def print_institution_data(data):
    spacing = "  "

# --- Institution Info ---
    institution = data.get("institution", {})
    print(f"{spacing}Institution: {institution.get('institution_name', 'N/A')}")
    print(f"{spacing}  Type: {institution.get('institution_type', 'N/A')}")
    print(f"{spacing}  Address: {institution.get('street', '')}, {institution.get('city', '')}, "
          f"{institution.get('state', '')} {institution.get('zipcode', '')}")
    print(f"{spacing}  Phone: {institution.get('institution_phone', 'N/A')}")
    print()

    # --- Departments ---
    departments = data.get("departments", {})
    for dept_key, dept in departments.items():
        print(f"{spacing}Department: {dept.get('department_name', dept_key)}")
        print(f"{spacing}  Email: {dept.get('department_email', 'N/A')}")
        print(f"{spacing}  Phone: {dept.get('department_phone', 'N/A')}")
        print()

        # --- People ---
        people = dept.get("people", {})
        for person_name, person_data in people.items():
            print(f"{spacing}  Name: {person_name}")
            print(f"{spacing}    Title/Bio: {person_data.get('bio', 'N/A')}")
            print(f"{spacing}    Email: {person_data.get('person_email', 'N/A')}")
            print(f"{spacing}    Phone: {person_data.get('person_phone', 'N/A')}")
            print(f"{spacing}    Profile: {person_data.get('profile_url', 'N/A')}")
            
            # Expertise
            expertise = [person_data.get(f"expertise_{i}") for i in range(1, 4)]
            expertise = [e for e in expertise if e]
            if expertise:
                print(f"{spacing}    Expertise: {', '.join(expertise)}")
            
            # Projects
            projects = person_data.get("projects", [])
            if projects:
                print(f"{spacing}    Projects:")
                for i, project in enumerate(projects, start=1):
                    print(f"{spacing}      Project {i}:")
                    print(f"{spacing}        Title: {project.get('project_title', 'N/A')}")
                    print(f"{spacing}        Description: {project.get('project_description', 'N/A')}")
                    print(f"{spacing}        Start Date: {project.get('start_date', 'N/A')}")
                    print(f"{spacing}        End Date: {project.get('end_date', 'N/A')}")
            print()  # newline between people
        print("-" * 60)  # separator between departments
        print()

def extract_apa_details(citation):

    details = {
        'author': None,
        'year': None,
        'title': None,
        'source': None
    }
    
    # Extract author (everything before the year)
    author_match = re.match(r'([^(]+)', citation)
    if author_match:
        details['author'] = author_match.group(1).strip()
    
    # Extract year in parentheses
    year_match = re.search(r'\((\d{4})\)', citation)
    if year_match:
        details['year'] = year_match.group(1)
    
    # Extract title (usually in quotes)
    title_match = re.search(r'"([^"]+)"', citation)
    if title_match:
        details['title'] = title_match.group(1)
    
    # Extract source/journal (usually italicized, we'll look for common patterns)
    # In plain text, italics might be indicated by underscores or just be the last part
    source_match = re.search(r'(?:_|In\s)([^.,]+)(?:[.,]|\d{4}|$)', citation)
    if source_match:
        details['source'] = source_match.group(1).strip()
    
    return details

def check_apa7_citation(citation_text):
    """
    Checks if a given text string likely represents an APA 7th edition citation.
    This is a simplified check and may not cover all APA 7th edition nuances.
    """

    # Regex for common author-date in-text citation (e.g., (Smith, 2023))
    in_text_pattern = r"\((?:[A-Za-zÀ-ÖØ-öø-ÿ]+(?:, [A-Za-zÀ-ÖØ-öø-ÿ]+\.?)*|et al\.), (?:19|20)\d{2}(?:, p\. \d+)?\)"
    
    # Regex for a basic reference list entry (Author, A. A. (Year). Title. Source.)
    # This is a very simplified example and would need significant expansion for full coverage.
    reference_pattern = r"^[A-Za-zÀ-ÖØ-öø-ÿ]+, [A-Z]\. ?(?:[A-Z]\.)? \((?:19|20)\d{2}\)\. .*?\."

    is_in_text = bool(re.search(in_text_pattern, citation_text))
    is_reference_entry = bool(re.match(reference_pattern, citation_text))

    # Regex to find in-text citations (Author, Year) or (Author & Author, Year)
    regex = r"\((?:[A-Za-z\s&,.]+), (\d{4})\)"

    matches = re.findall(regex, citation_text)
    print('matches:', matches)
    if is_in_text:
        return "Likely APA 7th edition in-text citation."
    elif is_reference_entry:
        return "Likely a simplified APA 7th edition reference list entry."
    else:
        return "Does not strongly resemble a typical APA 7th edition citation."


if __name__ == '__main__':

    path = Path("../data/pre_cleaning_usm_data.json")
    with path.open("r", encoding="utf-8") as f:
        data = json.load(f)

    # using the baseline loop from the print function to iterate through departments and people
    departments = data.get("departments", {})
    for dept_key, dept in departments.items():
        print(f"Department: {dept.get('department_name', dept_key)}")
        print(f"  Email: {dept.get('department_email', 'N/A')}")
        print(f"  Phone: {dept.get('department_phone', 'N/A')}")
        print()
        people = dept.get("people", {})
        for person_name, person_data in people.items():
            print(f" Name: {person_name}")
            print(f"   Title/Bio: {person_data.get('bio', 'N/A')}")
            
            curr_title = person_data.get('bio', 'N/A')
            # If nothing exists, set to None
            if curr_title == '':
                person_data['bio'] = None
            
            # 207-780-4291 is a placeholder phone number used when no phone is available, so remove it
            if(person_data.get('person_phone') == '207-780-4291'):
                person_data['person_phone'] = None
                
            # Expertise
            expertise = [person_data.get(f"expertise_{i}") for i in range(1, 4)]
            expertise = [e for e in expertise if e]
            if expertise:
                print(f"   Expertise: {', '.join(expertise)}")
            
            # Projects
            projects = person_data.get("projects", [])
            if projects:
                print(f"   Projects:")
                for i, project in enumerate(projects, start=1):
                    print(f"      Project {i}:")
                    print(f"        Title: {project.get('project_title', 'N/A')}")
                    if project.get('project_title'):
                        citation_check = check_apa7_citation(project.get('project_title'))
                        print(f"        Citation Check: {citation_check}")
                    print(f"        Description: {project.get('project_description', 'N/A')}")
                    print(f"        Start Date: {project.get('start_date', 'N/A')}")
                    print(f"        End Date: {project.get('end_date', 'N/A')}")
            print()  # newline between people
        print("-" * 60)  # separator between departments
        print()


    # with open( "../data/post_cleaning_usm_data.json", 'w') as f:
    #     json.dump(data, f, indent=4) 