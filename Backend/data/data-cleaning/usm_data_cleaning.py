"""
Filename: department_data_cleaning.py
Author: Lucas Matheson
Edited by: Lucas Matheson
Date: November 10, 2025


This data is currently in a nested dictionary format, with departments as keys
and people as nested keys within each department. This format is good for inserting
the data into the relational database by iterating over the dictionary and grabbing
each object and its properties to insert it into the database using defined procedures.

The data has many properties that can be cleaned and split into multiple columns. For example,
some projects are apa 7 citations that can be split into authors, year, title, etc. This
can cover more columns and add more people into the database.
"""

import json
from pathlib import Path
import re
from openai import OpenAI


#  AI generated by ChatGPT to print the data in a readable format
#  Primarily for debugging purposes
def print_institution_data(data):
    spacing = "  "

    # --- Institution Info ---
    institution = data.get("institution", {})
    print(f"{spacing}Institution: {institution.get('institution_name', 'N/A')}")
    print(f"{spacing}  Type: {institution.get('institution_type', 'N/A')}")
    print(
        f"{spacing}  Address: {institution.get('street', '')}, {institution.get('city', '')}, "
        f"{institution.get('state', '')} {institution.get('zipcode', '')}"
    )
    print(f"{spacing}  Phone: {institution.get('institution_phone', 'N/A')}")
    print()

    # --- Departments ---
    departments = data.get("departments", {})
    for dept_key, dept in departments.items():
        print(f"{spacing}Department: {dept.get('department_name', dept_key)}")
        print(f"{spacing}  Email: {dept.get('department_email', 'N/A')}")
        print(f"{spacing}  Phone: {dept.get('department_phone', 'N/A')}")
        print()

        # --- People ---
        people = dept.get("people", {})
        for person_name, person_data in people.items():
            print(f"{spacing}  Name: {person_name}")
            print(f"{spacing}    Title/Bio: {person_data.get('bio', 'N/A')}")
            print(f"{spacing}    Email: {person_data.get('person_email', 'N/A')}")
            print(f"{spacing}    Phone: {person_data.get('person_phone', 'N/A')}")
            print(f"{spacing}    Profile: {person_data.get('profile_url', 'N/A')}")

            # Expertise
            expertise = [person_data.get(f"expertise_{i}") for i in range(1, 4)]
            expertise = [e for e in expertise if e]
            if expertise:
                print(f"{spacing}    Expertise: {', '.join(expertise)}")

            # Projects
            projects = person_data.get("projects", [])
            if projects:
                print(f"{spacing}    Projects:")
                for i, project in enumerate(projects, start=1):
                    print(f"{spacing}      Project {i}:")
                    print(
                        f"{spacing}        Title: {project.get('project_title', 'N/A')}"
                    )
                    print(
                        f"{spacing}        Description: {project.get('project_description', 'N/A')}"
                    )
                    print(
                        f"{spacing}        Start Date: {project.get('start_date', 'N/A')}"
                    )
                    print(
                        f"{spacing}        End Date: {project.get('end_date', 'N/A')}"
                    )
            print()  # newline between people
        print("-" * 60)  # separator between departments
        print()


def extract_apa_details(citation):

    details = {"author": None, "year": None, "title": None, "source": None}

    # Extract author (everything before the year)
    author_match = re.match(r"([^(]+)", citation)
    if author_match:
        details["author"] = author_match.group(1).strip()

    # Extract year in parentheses
    year_match = re.search(r"\((\d{4})\)", citation)
    if year_match:
        details["year"] = year_match.group(1)

    # Extract title (usually in quotes)
    title_match = re.search(r'"([^"]+)"', citation)
    if title_match:
        details["title"] = title_match.group(1)

    # Extract source/journal (usually italicized, we'll look for common patterns)
    # In plain text, italics might be indicated by underscores or just be the last part
    source_match = re.search(r"(?:_|In\s)([^.,]+)(?:[.,]|\d{4}|$)", citation)
    if source_match:
        details["source"] = source_match.group(1).strip()

    return details


def check_apa7_citation(citation_text):
    """
    Checks if a given text string likely represents an APA 7th edition citation.
    This is a simplified check and may not cover all APA 7th edition nuances.
    """

    # Regex for common author-date in-text citation (e.g., (Smith, 2023))
    in_text_pattern = r"\((?:[A-Za-zÀ-ÖØ-öø-ÿ]+(?:, [A-Za-zÀ-ÖØ-öø-ÿ]+\.?)*|et al\.), (?:19|20)\d{2}(?:, p\. \d+)?\)"

    # Regex for a basic reference list entry (Author, A. A. (Year). Title. Source.)
    # This is a very simplified example and would need significant expansion for full coverage.
    reference_pattern = (
        r"^[A-Za-zÀ-ÖØ-öø-ÿ]+, [A-Z]\. ?(?:[A-Z]\.)? \((?:19|20)\d{2}\)\. .*?\."
    )

    is_in_text = bool(re.search(in_text_pattern, citation_text))
    is_reference_entry = bool(re.match(reference_pattern, citation_text))

    # Regex to find in-text citations (Author, Year) or (Author & Author, Year)
    regex = r"\((?:[A-Za-z\s&,.]+), (\d{4})\)"

    matches = re.findall(regex, citation_text)
    print("matches:", matches)
    if is_in_text:
        return "Likely APA 7th edition in-text citation."
    elif is_reference_entry:
        return "Likely a simplified APA 7th edition reference list entry."
    else:
        return "Does not strongly resemble a typical APA 7th edition citation."


def clean_unicode_escapes(str: str) -> str:
    # Handle JSON-escaped quotes first
    cleaned = str.replace('\\"', '"')
    # Decode escape sequences like \u2013 into actual characters
    decoded = cleaned.encode("utf-8").decode("unicode_escape")
    # Remove any remaining non-ASCII characters
    cleaned = decoded.encode("ascii", "ignore").decode("ascii")
    #  remove any random backslashes
    cleaned = cleaned.replace("\\\"", "")
    # Remove carriage returns and replace line feeds with spaces
    cleaned = cleaned.replace("\r", "").replace("\n", " ")
    # Clean up multiple spaces, tabs, etc. into single spaces
    cleaned = " ".join(cleaned.split())

    return cleaned

def clean_phone_number(phone: str) -> str:

    # Some phone numbers have unnessary spaces or leading country codes like '1' for US numbers, first remove the leading '1'
    cleaned = phone.lstrip("1")

    # Remove any remaining non-numeric characters
    cleaned = re.sub(r"[^\d]", "", cleaned)

    # Format the cleaned number to ensure all phone numbers follow a strict formation 
    # Example: "(123) 456-7890"
    if len(cleaned) == 10:
        cleaned = f"({cleaned[:3]}) {cleaned[3:6]}-{cleaned[6:]}"

    return cleaned

if __name__ == "__main__":

    path = Path("../unprocessed/pre_cleaning_usm_data.json")
    with path.open("r", encoding="utf-8") as f:
        data = json.load(f)

    # this will save all data that will be used to generate tags for expertise 1 to 3, along with a main field
    expertise_data = []

    # using the baseline loop from the print function to iterate through departments and people

    departments = data.get("departments", {})
    for dept_key, dept in departments.items():
        print(f"Department: {dept.get('department_name', dept_key)}")

        expertise_data.append(dept.get("department_name", dept_key))

        print(f"  Email: {dept.get('department_email', 'N/A')}")
        print(f"  Phone: {dept.get('department_phone', 'N/A')}")
        print()
        people = dept.get("people", {})
        # Create a snapshot before iterating, we will be changing the data so creating a snapshot of this
        # enables us to edit the data
        people_items = list(people.items())  

        for person_name, person_data in people_items:
            print(f" Name: {person_name}")
            print(f"   Title/Bio: {person_data.get('bio', 'N/A')}")

            curr_title = person_data.get("bio", "N/A")
            # If nothing exists, set to None
            if curr_title == "":
                person_data["bio"] = None
            curr_bio = clean_unicode_escapes(curr_title)
            person_data["bio"] = curr_bio

            # Remove department name from bio, often is found at start
            person_data["bio"] = curr_bio.replace(dept_key, " ")
            expertise_data.append(person_data["bio"])
            # \u00a0 is also found in the person key sometimes, so clean that too
            copy = person_name
            clean_name = clean_unicode_escapes(copy)
            
            # If the name after running through cleaning is different, then it needs to 
            # be updated by updating the key in the people dictionary
            # This removes the object with the old key and adds it back with the new key
            if clean_name != person_name:
                people[clean_name] = people.pop(person_name)
                person_name = clean_name

            curr_phone = person_data.get("person_phone", "")

            cleaned_phone = clean_phone_number(curr_phone)
            person_data["person_phone"] = cleaned_phone
            
            # Projects
            projects = person_data.get("projects", [])
            if projects:
                print(f"   Projects:")
                for i, project in enumerate(projects, start=1):
                    print(f"      Project {i}:")
                    print(f"        Title: {project.get('project_title', 'N/A')}")
                    if project.get("project_title"):
                        project["project_title"] = clean_unicode_escapes(
                            project["project_title"]
                        )
                        expertise_data.append(project["project_title"])
                        citation_check = check_apa7_citation(
                            project.get("project_title")
                        )
                        print(f"        Citation Check: {citation_check}")
                    print(
                        f"        Description: {project.get('project_description', 'N/A')}"
                    )
                    print(f"        Start Date: {project.get('start_date', 'N/A')}")
                    print(f"        End Date: {project.get('end_date', 'N/A')}")
            # # example response "High Performance Computing, Data Science Education, Machine Learning Research"
            # response = client.responses.create(
            #     model="gpt-5-nano",
            #     input="You are an expert at creating a comprehensive overview of the following expertise areas: "
            #     + (" ".join(map(str, expertise_data)))
            #     + """, generate four concise expertise tags that best represent the combined expertise areas listed. 
            # Each tag should be no more than three words long and should capture the essence of the expertise described. 
            # The first tag in the list should be the most relevant overall expertise area.
            # Provide the tags in a comma-separated format. Do not say anything else other than the tags""",
            #     store=True,
            # )

            # print(response.output_text)
            # expertise_tags = response.output_text.split(",")
            # # Assign the generated tags to main_field, expertise_1, expertise_2, expertise_3
            # for i, tag in enumerate(expertise_tags):
            #     if i == 0:
            #         person_data["main_field"] = tag.strip()
            #     if i < 4:
            #         person_data[f"expertise_{i + 1}"] = tag.strip()




    with open("../processed/post_cleaning_usm_data.json", "w") as f:
        json.dump(data, f, indent=4)
